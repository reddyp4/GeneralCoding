{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tawgZEiu-rx-"
   },
   "source": [
    "Problem Statement:\n",
    "\n",
    "**Suppose you are a data scientist working for a bank that recently conducted a marketing campaign to promote term deposits to its clients. The bank collected data on various client characteristics, such as age, job type, marital status, education level, and more. Your task is to analyze this dataset and build a machine learning model to predict whether a client will subscribe to a term deposit or not.**\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "**By accurately predicting client subscription behavior, your model will enable the bank to optimize its marketing efforts. It will help identify potential clients who are more likely to subscribe to the term deposit, allowing the bank to focus its resources on targeting these individuals. This targeted approach will not only increase the effectiveness of the marketing campaign but also maximize the bank's return on investment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN0GSwQS_HUU"
   },
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6mPd94Hy2zu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDK_wVtZ68S4"
   },
   "source": [
    "## Upload data to colab and Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QBKx7Cj6yIi"
   },
   "outputs": [],
   "source": [
    "# Write your code here::: Read the csv file. Hint: to read it perfectly or to load it perfectly in the dataframe you will need a seperator.\n",
    "df = pd.read_csv('bank-additional-full.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pC26-ZR7G7d"
   },
   "source": [
    "## Data Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uif1603J6teL"
   },
   "source": [
    "## Understand the data columns\n",
    "1. Check if there are missing values and decide either to impute or drop them\n",
    "2. Understand descriptive statistics of each columns\n",
    "3. Understand descriptive statistics of each column using pandas descibe\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "By default describe returns numerical columns. How do you also understand descriptive statistics for non numerical columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpQM89v37HTM"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfTBSGev7SL3"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eip8zWf97k6_"
   },
   "outputs": [],
   "source": [
    "# Write you code here:: to check if there is any missing value for every feature.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2uBg4nM7m_q"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Keep only those features with less than 20% of missing values\n",
    "missing_report = df.isna().sum()/len(df)\n",
    "features_ss1 = missing_report[missing_report<0.2].index\n",
    "print(features_ss1) # SS1 stands for Subset 1\n",
    "df = df[features_ss1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtOGJGNX_SK0"
   },
   "source": [
    "## Please do the following steps\n",
    "\n",
    "1. Begin by conducting exploratory data analysis (EDA) to gain a comprehensive understanding of the dataset. Visualize the data, compute summary statistics, and identify any patterns or insights.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "2. Preprocess the dataset by handling missing values, addressing categorical variables, and performing necessary data transformations. This step ensures that the data is in a suitable format for machine learning algorithms.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "3. Split the dataset into training and testing sets for model evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41tRY2PM8Tqj"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My EDA will have 5 steps:\n",
    "1) Outcome Exploration\n",
    "2) Univariate Exploration of Quantitative Input Variables\n",
    "3) Univariate Exploration of Categorical Input Variables\n",
    "4) Bivariate Exploration of Quantitative Input Variables\n",
    "\n",
    "With more time we could do Bivariate Exploration with Outcome vs All Inputs.\n",
    "\n",
    "### 1) Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbHT-tYR8VIT"
   },
   "outputs": [],
   "source": [
    "# Write you code here::::: a countplot, take X-axis as \"y\"(from data)  \n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.countplot(data=df, x=\"y\")\n",
    "ax.set(xlabel='Term Deposit', ylabel='')\n",
    "ax.set_title('Subscribe Y Variable', size=20)\n",
    "\n",
    "yes_cases = (df['y']=='yes').sum()\n",
    "print(f'y=yes represents {round((yes_cases/len(df))*100,2)}% of the cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Quantitative X's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Quantitative from Categorical\n",
    "x_quantitative = ['age', 'duration', 'campaign', 'pdays','previous', 'emp.var.rate',\n",
    "                 'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "y = ['y']\n",
    "x_categorical = [feature for feature in df.columns if ((feature not in x_quantitative) and (feature not in y)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplot_visual(data: pd.DataFrame, columns: list[str]) -> None:\n",
    "  \"\"\"Create a histogram plot using a subset of variables specified.\n",
    "\n",
    "  Args:\n",
    "    data: Input data-frame containing variables we wish to plot.\n",
    "    columns: Listing of column-names we wish to plot (must be contained within data).\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots(2, 5, figsize=(15, 6))\n",
    "  fig.suptitle('Histogram for each numeric variable in our data',y=1, size=20)\n",
    "  ax=ax.flatten()\n",
    "  for i,feature in enumerate(columns):\n",
    "    # Setting option `kde=True` allows for a Kernel Density Estimate (i.e. PDF).\n",
    "    sns.histplot(data=data[feature],ax=ax[i], kde=True)\n",
    "  plt.tight_layout()\n",
    "\n",
    "# Invoke our function defined above.\n",
    "histplot_visual(data=df, columns=x_quantitative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in x_categorical:\n",
    "    print(df[x].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plots(data: pd.DataFrame, columns: list[str]) -> None:\n",
    "  \"\"\"Create multiple plots using a subset of variables specified.\n",
    "\n",
    "  Args:\n",
    "    data: Input data-frame containing variables we wish to plot.\n",
    "    columns: Listing of column-names we wish to plot (must be contained within data).\n",
    "  \"\"\"\n",
    "  fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "  fig.suptitle('Countplot for each categorical variable in our data',y=1, size=20)\n",
    "  axes=axes.flatten()\n",
    "  for i,feature in enumerate(columns):\n",
    "    # Setting option `kde=True` allows for a Kernel Density Estimate (i.e. PDF).\n",
    "    sns.countplot(data=data, x=feature, ax=axes[i])\n",
    "  plt.tight_layout()\n",
    "\n",
    "# Invoke our function defined above.\n",
    "count_plots(data=df, columns=x_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.corr(numeric_only=True),annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(df[['emp.var.rate','euribor3m', 'nr.employed']].corr(numeric_only=True),annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Findings\n",
    "- y=1 -> 11%\n",
    "- No Missings :)\n",
    "- pdays has too many 999\n",
    "- campaign, duration and previous are very skewed (log or categorization can help logistic regression)\n",
    "- A lot of Unknown in categorical variables\n",
    "- emp.var.rate is very correlated with euribor3m (Euro Interbank Offered Rate 3 months) and nr.employed\n",
    "### Proposed Actions\n",
    "- pdays=999 becames a binary variable\n",
    "- remove euribor3m\n",
    "- one-hot encoding for categorical variables\n",
    "### Extra proposed actions if we have time\n",
    "- Apply transformations to campaign, duration and previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Orze22fP7Yvd"
   },
   "source": [
    "# Feature transformation / Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laxB9RCZ7Zaj"
   },
   "outputs": [],
   "source": [
    "df['pdays999']=(df['pdays']==999)\n",
    "df = df.drop(['pdays','euribor3m'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical.append('pdays999')\n",
    "x_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laxB9RCZ7Zaj"
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=x_categorical, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyJLpCIT7Zza"
   },
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "# Splitting our dataset between training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfF_dkM-_ci1"
   },
   "source": [
    "Train and evaluate various classification models, such as logistic regression, support vector machines etc. Compare the performance of these models to identify the most accurate one for the task at hand.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Fine-tune the selected model by adjusting hyperparameters. Use regularization techniques.\n",
    "\n",
    "Ensure you transform the labels and feature data before you do this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AxAc8HA_IhE"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6ZqAXS9AOsr"
   },
   "source": [
    "**Logistic Regression**\n",
    "(Example provided)\n",
    "Please ensure you use the right metric to evaluate classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdUMSyVl_ai4"
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression model to the training data\n",
    "model1 = LogisticRegression(random_state = 42, max_iter = 1000)\n",
    "model1.fit(X_train, y_train)\n",
    "pred_test = model1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_test)\n",
    "print('Accuracy:', round(accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdUMSyVl_ai4"
   },
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "\n",
    "def accuracy_report(model,values_list):\n",
    "    '''This function will assess model performance. Given a sklearn model it will Predict, and measure performance for both Test and Train Data'''\n",
    "    #Train\n",
    "    print('Train Data:\\n-----------')\n",
    "    pred_train = model.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, pred_train)\n",
    "    print('Accuracy:', round(accuracy_train,4))\n",
    "    print(classification_report(y_train, pred_train, target_names = values_list))\n",
    "    roc_plot(model,X_train,y_train,values_list)\n",
    "    \n",
    "    print('Test Data:\\n----------')\n",
    "    pred_test = model.predict(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, pred_test)\n",
    "    print('Accuracy:', round(accuracy_test,4))\n",
    "    print(classification_report(y_test, pred_test, target_names = values_list))\n",
    "    roc_plot(model,X_test,y_test,values_list)\n",
    "\n",
    "\n",
    "def roc_plot(model,X_data,y_data,values_list):\n",
    "    y_scores = model.predict_proba(X_data)[:, 1]\n",
    "    y_data = y_data.map({values_list[0]:0,values_list[1]:1})\n",
    "    fpr, tpr, thresholds = roc_curve(y_data, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report(model1,['no','yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AAuY0oc8lZw"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model2 = SVC(kernel='linear', C=1, probability=True)\n",
    "model2.fit(X_train, y_train)\n",
    "accuracy_report(model2,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model3 = SVC(kernel='linear', C=0.5, probability=True)\n",
    "model3.fit(X_train, y_train)\n",
    "accuracy_report(model3,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = SVC(kernel='poly', C=1, probability=True)\n",
    "model4.fit(X_train, y_train)\n",
    "accuracy_report(model4,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = SVC(kernel='rbf', C=1, probability=True)\n",
    "model5.fit(X_train, y_train)\n",
    "accuracy_report(model5,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DONsqwfR8lXL"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model6 = KNeighborsClassifier(n_neighbors=3)\n",
    "model6.fit(X_train, y_train)\n",
    "accuracy_report(model6,['no','yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a known [issue](https://github.com/scikit-learn/scikit-learn/issues/26768) with predict and knn. I will create a second version of our assessment function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_report_v2(model,values_list):\n",
    "    '''This function will assess model performance. Given a sklearn model it will Predict, and measure performance for both Test and Train Data'''\n",
    "    #Train\n",
    "    print('Train Data:\\n-----------')\n",
    "    pred_train = model.predict(X_train.values)\n",
    "    accuracy_train = accuracy_score(y_train, pred_train)\n",
    "    print('Accuracy:', round(accuracy_train,4))\n",
    "    print(classification_report(y_train, pred_train, target_names = values_list))\n",
    "    roc_plot_v2(model,X_train,y_train,values_list)\n",
    "    \n",
    "    print('Test Data:\\n----------')\n",
    "    pred_test = model.predict(X_test.values)\n",
    "    accuracy_test = accuracy_score(y_test, pred_test)\n",
    "    print('Accuracy:', round(accuracy_test,4))\n",
    "    print(classification_report(y_test, pred_test, target_names = values_list))\n",
    "    roc_plot_v2(model,X_test,y_test,values_list)\n",
    "\n",
    "\n",
    "def roc_plot_v2(model,X_data,y_data,values_list):\n",
    "    y_scores = model.predict_proba(X_data.values)[:, 1]\n",
    "    y_data = y_data.map({values_list[0]:0,values_list[1]:1})\n",
    "    fpr, tpr, thresholds = roc_curve(y_data, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report_v2(model6,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DONsqwfR8lXL"
   },
   "outputs": [],
   "source": [
    "model7 = KNeighborsClassifier(n_neighbors=5, algorithm = 'ball_tree')\n",
    "model7.fit(X_train, y_train)\n",
    "accuracy_report_v2(model7,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = KNeighborsClassifier(n_neighbors=8, algorithm = 'ball_tree') #Finding the optimal k raises a discussion of validation data set\n",
    "model8.fit(X_train, y_train)\n",
    "accuracy_report_v2(model8,['no','yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model9 = GaussianNB()\n",
    "model9.fit(X_train, y_train)\n",
    "accuracy_report(model9,['no','yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQCaccR3_0gM"
   },
   "source": [
    "**Write a report**\n",
    "\n",
    "\n",
    "Assess the model's performance using appropriate evaluation metrics such as accuracy, precision, recall, and F1-score. This evaluation will provide insights into how well the model can predict client subscription behavior.\n",
    "\n",
    "\n",
    "Finally, present your findings and recommendations in a comprehensive report. Include details about the model's predictions, feature importance, and any potential insights gained from the analysis. Conclude the report with actionable recommendations for the bank based on the developed model.\n",
    "\n",
    "\n",
    "As a data scientist, your deliverables will consist of a well-documented Jupyter Notebook or Python script that showcases your analysis, modeling approach, evaluation results, and conclusions. Additionally, prepare a comprehensive report summarizing your findings and recommendations for the bank based on the insights gained from the developed model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
